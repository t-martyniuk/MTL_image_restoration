---
project: multi_task_learning
experiment_desc: mtl_9_3tasks_fpn
phase: train
warmup_num: 3
model:
    g_name: fpn_inception
    blocks: 9
    d_name: n_layers
    d_layers: 3
    fea_loss: perceptual
    pixel_loss: l2
    disc_loss: wgan-gp
    learn_residual: True
    backbone: resnet34
    pretrained: False
    norm_layer: instance
    dropout: True  
num_epochs: 80
num_workers: 4
datasets:
  - type: unaligned
    batch_size: 2
#    dataroot_train: /home/ml/datasets/GOPRO_Large_3840_FPS
#    dataroot_val: /home/ml/datasets/GOPRO_Large_3840_FPS
    dataroot_train: /home/tanya/datasets/GOPRO_Large_3840_FPS
    dataroot_val: /home/tanya/datasets/GOPRO_Large_3840_FPS
    fineSize: 256
  - type: haze
    batch_size: 1
#    dataroot_train: /home/ml/datasets/d_hazy
#    dataroot_val: /home/ml/datasets/d_hazy
    dataroot_train: /home/tanya/datasets/d_hazy
    dataroot_val: /home/tanya/datasets/d_hazy
    fineSize: 256
  - type: rain
    batch_size: 1
#    dataroot_train: /home/ml/datasets/raindrop_data
#    dataroot_val: /home/ml/datasets/raindrop_data
    dataroot_train: /home/tanya/datasets/raindrop_data
    dataroot_val: /home/tanya/datasets/raindrop_data
    fineSize: 256
image_size: [256, 256]
D_update_ratio: 1
loss:
    adv: 0.01
    l1: 0
optimizer:
    name: adam
    lr_G: 0.0001
    lr_D: 0.0002
scheduler:
    name: linear
    start_epoch: 40
    min_lr: 0.0000001

